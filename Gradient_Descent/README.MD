# Gradient Descent in 2-D Regression

Implement Gradient Descent and plot the error surface
The dataset is download from Kaggle. Here is the [link](https://www.kaggle.com/shivam2503/diamonds)

Only using first 10000 data points, can use whole data points but take longer time

2-D regression, find the relation between mass and price
price = m*mass + b (m: slope, b: bias)

### Requirement:
*Numpy
*Pandas
*matplotlib



```
python SGD_2D.py
```


### The fit line after gradient descent
![Image of fit line](https://github.com/GaryLMS/The_math_of_intelligence/tree/master/Gradient_Descent/image/fit_line.png)

### The error surface with parameter m and b
![Image of Error surface](https://github.com/GaryLMS/The_math_of_intelligence/tree/master/Gradient_Descent/image/Error_surface.png)
